{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_ver1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepthi-skive/gpt-2/blob/master/GPT2_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wfx_44enhm8",
        "outputId": "b330b56d-3e49-43c7-dcde-8b875db09ae3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgUGtGN-wNua"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEQ55aHvno2C",
        "outputId": "a6625e28-bab8-4e8a-8328-a14047196d73"
      },
      "source": [
        "# Create gpt-2 folder \r\n",
        "#Run only once\r\n",
        "%cd /content/drive/My\\ Drive/\r\n",
        "!mkdir gpt-2\r\n",
        "%cd gpt-2/\r\n",
        "# Clone GPT2 repo from OPenAI github\r\n",
        "!git clone https://github.com/openai/gpt-2.git \r\n",
        "# Change directory to gpt-2\r\n",
        "%cd cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/gpt-2\n",
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 233 (delta 0), reused 1 (delta 0), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (233/233), 4.38 MiB | 11.86 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n",
            "[Errno 2] No such file or directory: 'cd gpt-2'\n",
            "/content/drive/My Drive/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWfzu2SoPqb",
        "outputId": "3870fa08-a79e-4665-b0d8-151cc2d645b7"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/gpt-2/gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4v5tRnZoW3f",
        "outputId": "b785ec9d-6b61-421a-c0f0-32e46561eb1c"
      },
      "source": [
        "# Change tensorflow version to 1. \r\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yawEXJ2_odWg",
        "outputId": "35ec7aa0-4d0b-4a0d-dd79-aed679c3824f"
      },
      "source": [
        "# Install requirement.txt\r\n",
        "!pip3 install -r requirements.txt\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTnjwu8yoirO",
        "outputId": "855eec43-3a8a-49df-b882-2bcc0a254d43"
      },
      "source": [
        "#Importing all 4 versions of GPT2 model\r\n",
        "!python3 download_model.py 124M\r\n",
        "!python3 download_model.py 355M\r\n",
        "!python3 download_model.py 774M\r\n",
        "!python3 download_model.py 1558M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 851kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 1.99Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 808kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:16, 30.0Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 1.47Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 1.40Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.29Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFj6h1kQpThd",
        "outputId": "9d5cd20b-3afa-4441-c966-63d6a4f33a5e"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py -- --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mNAME\u001b[0m\n",
            "    interactive_conditional_samples.py - Interactively run the model :model_name=124M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :models_dir : path to parent folder containing model subfolders (i.e. contains the <model_name> folder)\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    interactive_conditional_samples.py <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    Interactively run the model :model_name=124M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :models_dir : path to parent folder containing model subfolders (i.e. contains the <model_name> folder)\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    --model_name=\u001b[4mMODEL_NAME\u001b[0m\n",
            "    --seed=\u001b[4mSEED\u001b[0m\n",
            "    --nsamples=\u001b[4mNSAMPLES\u001b[0m\n",
            "    --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
            "    --length=\u001b[4mLENGTH\u001b[0m\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "    --top_k=\u001b[4mTOP_K\u001b[0m\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "    --models_dir=\u001b[4mMODELS_DIR\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfoPzWvVo3Rj",
        "outputId": "1b0fa825-7747-44bf-bbb9-65e25f818097"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-10 21:26:48.677163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-10 21:26:48.803932: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-10 21:26:48.803999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1f9317368c0e): /proc/driver/nvidia/version does not exist\n",
            "2020-12-10 21:26:48.872787: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-12-10 21:26:48.873592: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x296b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-10 21:26:48.873677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2020-12-10 21:26:56.989860: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "Model prompt >>> Today in popular news\n",
            "2020-12-10 21:28:01.853572: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 20717568 exceeds 10% of system memory.\n",
            "2020-12-10 21:28:01.933898: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 20791296 exceeds 10% of system memory.\n",
            "2020-12-10 21:28:02.011456: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 20865024 exceeds 10% of system memory.\n",
            "2020-12-10 21:28:02.092837: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 20938752 exceeds 10% of system memory.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " outlets, there are various headlines from the news outlets which report that the \"ISIS\" organization has captured a massive number of terrorists who have taken refuge overseas. In addition, a senior government official indicated that ISIS has not been able to fully \"understand\" the United States as a nation and has therefore been able to take control of the territory.\n",
            "\n",
            "However, ISIS does not appear to care about these developments even when they occur overseas. And since ISIS is now completely under your control in the United States, what could these attacks be, besides gaining international notoriety and \"control\" of many of America's main tourist attractions? Here in Turkey for example, the United States is only able to control the territory of one or both of these three Muslim nations: Iraq, Syria and Jordan (except for the border between Turkey and Lebanon).\n",
            "\n",
            "If ISIS controlled the territory of any countries, what would be the consequences?\n",
            "\n",
            "It is important to note that the Islamic State's actions against the United States have a direct impact upon Turkey and America's allies in the region. It has attacked and destroyed multiple military bases, many of which have been in the Syrian civil war over nearly 1,000 years of history. The United States is not the only NATO member that has been in the crosshairs of the Islamic State, but since ISIS controls such significant territory in Iraq, Syria, and Jordan alone, there are likely to be the consequences there.<|endoftext|>From MTG Wiki\n",
            "\n",
            "Sarut of Woe is a card spell you may cast in any order from hand to graveyard. It doesn't remove combat damage or enchantments, but it has synergy with many other spells and synergizes well with other spells and spells that deal large amounts of damage. You can create a lot of copies if you control at least two of these cards.\n",
            "\n",
            "You can also find these cards in other lands, such as:\n",
            "\n",
            "It is possible to put sarsanut and it's sister Sarut into one game, but a lot of people are missing it. You can also see sarsanut being included by playing some random land in the draft table.\n",
            "\n",
            "There are a lot of different card choices between the sarsanut family and other spells and monsters. There are also a lot of spells and enchantments used to combat the sarsanut of a land.<|endoftext|>A new study published in the journal Current Biology claims that there is a large amount of evidence in favor of a causal link between cancer and vitamin D intake and health.\n",
            "================================================================================\n",
            "Model prompt >>> Donald Trump \n",
            "======================================== SAMPLE 1 ========================================\n",
            "ㅠ — Kim Jong Un (@KoreaUn) May 18, 2017\n",
            "\n",
            "(Featured image is from Kim Jong Un photo)<|endoftext|>Still loading...\n",
            "\n",
            "A B C D E F G H I J K L M N O P Q R S T U V W X Y Z AA AB 1 Name 2 Determination Bonus Effect Name 3 2: I am the only you. The first time you see me 2 3 2 1 2 9 9 0.2 5 4 3 3 3 2 5 4 5 5 0 7 8 7 0 2 5 6 7 3 2 0 0.4 9 7 6 1 1 1 6 6 4 4 0 0.6 10 8 2 0 2 5 3 5 1 10 0 10 11 9 0 2\n",
            "\n",
            "12 9 5 1 2 2 1 5 7 1 8 4 6 4 13 6 4 7 27 10 8 1 0 0.2 12 11 3 0 1 5 2 5 5 10 1 13 0 1 0 0.4 13 12 6 3 2 1 6 6 3 4 14 3 5 7 4 4 11 1 15 4 5 10 14 5 2 26 16 6 7 25 17 0 1\n",
            "\n",
            "18 13 4 2 2 1 1 6 6 10 11 10 12 3 10 17 10 10 27 10 10 9 18 19 0 1\n",
            "\n",
            "20 14 4 0 2 1 1 5 4 12 8 11 10 17 10 11 30 23 10 15 20 21 0 1\n",
            "\n",
            "22 15 0 3\n",
            "\n",
            "23 18 4 0 0 1 4 2 3 8 12 11 12 3 12 23 18 14 2 1 24 16 3 0 6 1 7 1 9 13 4 23 18 16 16 15 1 25 19 3 2\n",
            "\n",
            "26 20 3 6 5 5 10 12 3 7 13 11 12 9 6 4 23 15 10 10 32 16 7 0 28 15 4 3 1 6 9 5 5 11 4 31 4 9 23 14 14 5 17 26 27 21 7 26 24 10 32 28 0 7 3 2 19 8 11 9 9 5 3 17 17 23 10 7 33 28 3 7 11 12 9 6 24 15 20 10 27 16 6 36 29 0 7 8 4 8 12 16 5 20 19 17 13 12 34 29 2 11 6 12 17 8 20 12 16 2 28 33 11 12 6 15 10 32 30 2 13 6 13 18 10 12 12 10 3 9 13 24 17 13 13 5 36 31 2 12 10 10 12 13 13 16 4 15 25 6 17 26 30 20 10 36 31 0 7 8 9 9 12 12 20 16 16 6 35 32 0 11 7 9 9 15 10 10\n",
            "================================================================================\n",
            "Model prompt >>> "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}